{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 내 파일 개수: 14\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "file_count = len(file_list)  # 파일 개수 계산\n",
    "print(f\"폴더 내 파일 개수: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 리스트를 적절히 초기화해야 함\n",
    "idx = 0\n",
    "\n",
    "while True:\n",
    "    bgimg = cv2.imread(file_list[idx])\n",
    "    cv2.imshow('test', bgimg)\n",
    "    \n",
    "    key = cv2.waitKey(0)  # 키 입력 대기\n",
    "    \n",
    "    if key == ord('c'):\n",
    "        idx += 1\n",
    "        if idx >= len(file_list):\n",
    "            idx = 0\n",
    "    elif key == ord('z'):\n",
    "        idx -= 1\n",
    "        if idx < 0:\n",
    "            idx = len(file_list) - 1\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 94.9ms\n",
      "Speed: 4.0ms preprocess, 94.9ms inference, 403.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bgimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m         background \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tmp\n\u001b[0;32m     35\u001b[0m \u001b[39m# 배경 이미지를 원하는 배경으로 마스킹\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m bgimg_resized \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(bgimg, (frame\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], frame\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[0;32m     37\u001b[0m background \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(background \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, bgimg_resized, background)\n\u001b[0;32m     39\u001b[0m \u001b[39m# 마스킹된 이미지 출력\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bgimg' is not defined"
     ]
    }
   ],
   "source": [
    "# YOLOv8 모델 로드\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 적용할 배경\n",
    "# bgimg = cv2.imread('./yolobg.jpg')\n",
    "\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행 \n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0)\n",
    "\n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "        for result in results:\n",
    "            # print(result)\n",
    "            for mask in result.masks:\n",
    "                # 마스크 데이터에서 차원 축소\n",
    "                m = torch.squeeze(mask.data)\n",
    "                # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                composite = torch.stack((m, m, m), 2)\n",
    "                # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                # 추출된 마스크 영역을 배경에 누적\n",
    "                background += tmp\n",
    "\n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "\n",
    "        # 마스킹된 이미지 출력\n",
    "        cv2.imshow(\"웹캠 배경 마스킹\", background)\n",
    "\n",
    "        # 'q' 키가 눌리면 루프 종료\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사람이외에 학습된 객체 탐지를 발견\n",
    "- if문을 통해 사람만 마스킹해보려하였으나 실패\n",
    ">* ex)result.boxes.cls == 0\n",
    "- 홈페이지에서 탐지 객체를 지정하는 옵션을 발견해 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov8에서 탐지가능한 객체 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', \n",
    "# 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
    "# 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', \n",
    "# 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', \n",
    "# 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', \n",
    "# 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', \n",
    "# 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', \n",
    "# 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',\n",
    "# 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon',\n",
    "# 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange',\n",
    "# 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut',\n",
    "# 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed',\n",
    "# 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse',\n",
    "# 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven',\n",
    "# 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock',\n",
    "# 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
    "\n",
    "# 0: '사람', 1: '자전거', 2: '자동차', 3: '오토바이', 4: '비행기',\n",
    "# 5: '버스', 6: '기차', 7: '트럭', 8: '보트', 9: '신호등',\n",
    "# 10: '소화전', 11: '정지 신호', 12: '주차 미터', 13: '벤치', 14: '새',\n",
    "# 15: '고양이', 16: '개', 17: '말', 18: '양', 19: '소',\n",
    "# 20: '코끼리', 21: '곰', 22: '얼룩말', 23: '기린', 24: '배낭',\n",
    "# 25: '우산', 26: '핸드백', 27: '넥타이', 28: '여행가방', 29: '프리스비',\n",
    "# 30: '스키', 31: '스노보드', 32: '스포츠 공', 33: '연', 34: '야구 방망이',\n",
    "# 35: '야구 글러브', 36: '스케이트보드', 37: '서프보드', 38: '테니스 라켓', 39: '병',\n",
    "# 40: '와인 잔', 41: '컵', 42: '포크', 43: '칼', 44: '숟가락',\n",
    "# 45: '그릇', 46: '바나나', 47: '사과', 48: '샌드위치', 49: '오렌지',\n",
    "# 50: '브로콜리', 51: '당근', 52: '핫도그', 53: '피자', 54: '도넛',\n",
    "# 55: '케이크', 56: '의자', 57: '소파', 58: '화분', 59: '침대',\n",
    "# 60: '식탁', 61: '화장실', 62: 'TV', 63: '노트북', 64: '마우스',\n",
    "# 65: '리모컨', 66: '키보드', 67: '휴대폰', 68: '전자레인지', 69: '오븐',\n",
    "# 70: '토스터', 71: '싱크대', 72: '냉장고', 73: '책', 74: '시계',\n",
    "# 75: '꽃병', 76: '가위', 77: '테디 베어', 78: '헤어 드라이어', 79: '칫솔'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0: 'person'            ->      0: '사람'\n",
    "#  1: 'bicycle'           ->      1: '자전거'\n",
    "#  2: 'car'               ->      2: '자동차'\n",
    "#  3: 'motorcycle'        ->      3: '오토바이'\n",
    "#  4: 'airplane'          ->      4: '비행기'\n",
    "#  5: 'bus'               ->      5: '버스'\n",
    "#  6: 'train'             ->      6: '기차'\n",
    "#  7: 'truck'             ->      7: '트럭'\n",
    "#  8: 'boat'              ->      8: '보트'\n",
    "#  9: 'traffic light'     ->      9: '신호등'\n",
    "# 10: 'fire hydrant'      ->     10: '소화전'\n",
    "# 11: 'stop sign'         ->     11: '정지 신호'\n",
    "# 12: 'parking meter'     ->     12: '주차 미터'\n",
    "# 13: 'bench'             ->     13: '벤치'\n",
    "# 14: 'bird'              ->     14: '새'\n",
    "# 15: 'cat'               ->     15: '고양이'\n",
    "# 16: 'dog'               ->     16: '개'\n",
    "# 17: 'horse'             ->     17: '말'\n",
    "# 18: 'sheep'             ->     18: '양'\n",
    "# 19: 'cow'               ->     19: '소'\n",
    "# 20: 'elephant'          ->     20: '코끼리'\n",
    "# 21: 'bear'              ->     21: '곰'\n",
    "# 22: 'zebra'             ->     22: '얼룩말'\n",
    "# 23: 'giraffe'           ->     23: '기린'\n",
    "# 24: 'backpack'          ->     24: '배낭'\n",
    "# 25: 'umbrella'          ->     25: '우산'\n",
    "# 26: 'handbag'           ->     26: '핸드백'\n",
    "# 27: 'tie'               ->     27: '넥타이'\n",
    "# 28: 'suitcase'          ->     28: '여행가방'\n",
    "# 29: 'frisbee'           ->     29: '프리스비'\n",
    "# 30: 'skis'              ->     30: '스키'\n",
    "# 31: 'snowboard'         ->     31: '스노보드'\n",
    "# 32: 'sports ball'       ->     32: '스포츠 공'\n",
    "# 33: 'kite'              ->     33: '연'\n",
    "# 34: 'baseball bat'      ->     34: '야구 방망이'\n",
    "# 35: 'baseball glove'    ->     35: '야구 글러브'\n",
    "# 36: 'skateboard'        ->     36: '스케이트보드'\n",
    "# 37: 'surfboard'         ->     37: '서프보드'\n",
    "# 38: 'tennis racket'     ->     38: '테니스 라켓'\n",
    "# 39: 'bottle'            ->     39: '병'\n",
    "# 40: 'wine glass'        ->     40: '와인 잔'\n",
    "# 41: 'cup'               ->     41: '컵'\n",
    "# 42: 'fork'              ->     42: '포크'\n",
    "# 43: 'knife'             ->     43: '칼'\n",
    "# 44: 'spoon'             ->     44: '숟가락'\n",
    "# 45: 'bowl'              ->     45: '그릇'\n",
    "# 46: 'banana'            ->     46: '바나나'\n",
    "# 47: 'apple'             ->     47: '사과'\n",
    "# 48: 'sandwich'          ->     48: '샌드위치'\n",
    "# 49: 'orange'            ->     49: '오렌지'\n",
    "# 50: 'broccoli'          ->     50: '브로콜리'\n",
    "# 51: 'carrot'            ->     51: '당근'\n",
    "# 52: 'hot dog'           ->     52: '핫도그'\n",
    "# 53: 'pizza'             ->     53: '피자'\n",
    "# 54: 'donut'             ->     54: '도넛'\n",
    "# 55: 'cake'              ->     55: '케이크'\n",
    "# 56: 'chair'             ->     56: '의자'\n",
    "# 57: 'couch'             ->     57: '소파'\n",
    "# 58: 'potted plant'      ->     58: '화분'\n",
    "# 59: 'bed'               ->     59: '침대'\n",
    "# 60: 'dining table'      ->     60: '식탁'\n",
    "# 61: 'toilet'            ->     61: '화장실'\n",
    "# 62: 'tv'                ->     62: 'TV'\n",
    "# 63: 'laptop'            ->     63: '노트북'\n",
    "# 64: 'mouse'             ->     64: '마우스'\n",
    "# 65: 'remote'            ->     65: '리모컨'\n",
    "# 66: 'keyboard'          ->     66: '키보드'\n",
    "# 67: 'cell phone'        ->     67: '휴대폰'\n",
    "# 68: 'microwave'         ->     68: '전자레인지'\n",
    "# 69: 'oven'              ->     69: '오븐'\n",
    "# 70: 'toaster'           ->     70: '토스터'\n",
    "# 71: 'sink'              ->     71: '싱크대'\n",
    "# 72: 'refrigerator'      ->     72: '냉장고'\n",
    "# 73: 'book'              ->     73: '책'\n",
    "# 74: 'clock'             ->     74: '시계'\n",
    "# 75: 'vase'              ->     75: '꽃병'\n",
    "# 76: 'scissors'          ->     76: '가위'\n",
    "# 77: 'teddy bear'        ->     77: '테디 베어'\n",
    "# 78: 'hair drier'        ->     78: '헤어 드라이어'\n",
    "# 79: 'toothbrush'        ->     79: '칫솔'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경 변경버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 kite, 2 clocks, 53.0ms\n",
      "Speed: 4.0ms preprocess, 53.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Read an image using OpenCV\n",
    "source = cv2.imread('../BAX_HTP/data/dbi/24_175_23002_person.jpg')\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source)  # list of Results objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m'\u001b[39;49m, results)\n\u001b[0;32m      2\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('d', results)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  NMS time limit 0.550s exceeded\n",
      "0: 480x640 1 person, 93.1ms\n",
      "Speed: 5.0ms preprocess, 93.1ms inference, 729.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.1ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.3ms\n",
      "Speed: 1.0ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 12.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.3ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.2ms\n",
      "Speed: 1.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.8ms\n",
      "Speed: 2.2ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.5ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 2.0ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 2.0ms preprocess, 9.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 12.0ms\n",
      "Speed: 1.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 0.9ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.1ms\n",
      "Speed: 0.6ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 1.0ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8 모델 로드\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 배경을 불러오기\n",
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "file_count = len(file_list)  # 파일 개수 계산\n",
    "idx = 0 # 파일 리스트를 적절히 초기화해야 함\n",
    "\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행\n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0)\n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        \n",
    "        try: # 사람이 탐지되지않으면 오류나는것을 방지\n",
    "            for result in results:\n",
    "                # print(result.names) # 탐지 객체 목록 딕셔너리\n",
    "                # if result.boxes.conf >= 0.80:\n",
    "                    # print(result.boxes.conf)\n",
    "                    # if result.probs is not None and result.probs.top1 == 1:\n",
    "                    for mask in result.masks:\n",
    "                        # 마스크 데이터에서 차원 축소\n",
    "                        m = torch.squeeze(mask.data)\n",
    "                        # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                        composite = torch.stack((m, m, m), 2)\n",
    "                        # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                        tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                        # 추출된 마스크 영역을 배경에 누적\n",
    "                        # 미리 생성해둔 검은 배경에 세그먼트된 영역을 채워넣음\n",
    "                        background += tmp\n",
    "                # else:\n",
    "                #     # results = model(frame, classes=0)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg = cv2.imread(file_list[idx])\n",
    "        bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        # 검정색배경에 세그먼트된 영상에서 0인값을 설정해둔 배경으로 마스킹\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "        background = cv2.resize(background, (960,720))\n",
    "        # 마스킹된 이미지 출력\n",
    "        cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "            break\n",
    "        # 'c' 키가 눌리면 다음 배경\n",
    "        elif key == 99: # ord(\"c\")\n",
    "            idx += 1\n",
    "            if idx >= len(file_list):\n",
    "                idx = 0\n",
    "        # 'z' 키가 눌리면 이전 배경\n",
    "        elif key == 122: # ord(\"z\")\n",
    "            idx -= 1\n",
    "            if idx < 0:\n",
    "                idx = len(file_list) - 1\n",
    "\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 개선 방안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모션인식을 통한 배경 변경 예시) 오른쪽으로 손을 슬라이드하면 다음 배경 왼쪽 이전 배경\n",
    "* 추가 필터 효과\n",
    "* 스팀 프로필 효과같은것\n",
    "* 검출된 객체의 엣지를 배경색상과 비슷하게 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 4.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8 모델 로드\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 배경을 불러오기\n",
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "file_count = len(file_list)  # 파일 개수 계산\n",
    "idx = 0 # 파일 리스트를 적절히 초기화해야 함\n",
    "\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행\n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0)\n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        \n",
    "        try: # 사람이 탐지되지않으면 오류나는것을 방지\n",
    "            for result in results:\n",
    "                # print(result.names) # 탐지 객체 목록 딕셔너리\n",
    "                # if result.boxes.conf >= 0.80:\n",
    "                    # print(result.boxes.conf)\n",
    "                    # if result.probs is not None and result.probs.top1 == 1:\n",
    "                    for mask in result.masks:\n",
    "                        # 마스크 데이터에서 차원 축소\n",
    "                        m = torch.squeeze(mask.data)\n",
    "                        # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                        composite = torch.stack((m, m, m), 2)\n",
    "                        # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                        tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                        # 추출된 마스크 영역을 배경에 누적\n",
    "                        background += tmp\n",
    "                # else:\n",
    "                #     # results = model(frame, classes=0)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg = cv2.imread(file_list[idx])\n",
    "        bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        # 엣지 부분을 블러 처리하여 배경과 자연스럽게 통합\n",
    "        edges = cv2.Canny(background, 500, 500)  # 엣지 추출\n",
    "        blurred_edges = cv2.GaussianBlur(edges, (9, 9), 0)  # 엣지 블러 처리\n",
    "        # 엣지 부분을 검정색으로 처리\n",
    "        # background[blurred_edges != 0] = 255\n",
    "        # 배경과 마스킹된 이미지를 합성\n",
    "        # composite_img = cv2.add(background, bgimg_resized)\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "        # 마스킹된 이미지 출력\n",
    "        # cv2.imshow(\"Project\", cv2.flip(composite_img, 1))\n",
    "\n",
    "        # 마스킹된 이미지 출력\n",
    "        cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "            break\n",
    "        # 'c' 키가 눌리면 다음 배경\n",
    "        elif key == 99: # ord(\"c\")\n",
    "            idx += 1\n",
    "            if idx >= len(file_list):\n",
    "                idx = 0\n",
    "        # 'z' 키가 눌리면 이전 배경\n",
    "        elif key == 122: # ord(\"z\")\n",
    "            idx -= 1\n",
    "            if idx < 0:\n",
    "                idx = len(file_list) - 1\n",
    "\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모션인식을 위한 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next (109, 100)\n",
      "Next (79, 30, 100)\n",
      "Preview (130, 100)\n",
      "Preview (100, 30, 100)\n",
      "Cam_Off (155, 100)\n",
      "Cam_Off (125, 30, 100)\n",
      "Cam_On (168, 100)\n",
      "Cam_On (138, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os\n",
    "\n",
    "# 학습시킬 데이터 지정\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On']\n",
    "seq_length = 30 # window의 사이즈\n",
    "secs_for_action = 30 # 하나의 제스쳐를 찍는데 걸리는 시간\n",
    "\n",
    "# MediaPipe hands model\n",
    "\n",
    "# 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1, # 몇 개의 손을 인식할 것인지\n",
    "    min_detection_confidence = 0.5,\n",
    "    min_tracking_confidence = 0.5)\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "dirpath = './data/Mini_Project/motion/'\n",
    "created_time = int(time.time())\n",
    "os.makedirs(dirpath+'dataset', exist_ok=True) # 데이터 셋을 저장할 폴더 만들기\n",
    "\n",
    "# 웹캠을 열어서 데이터 모으기\n",
    "while cap.isOpened():\n",
    "    for idx, action in enumerate(actions):\n",
    "        data = []\n",
    "\n",
    "        # 이미지 읽기\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        # flip, 웹캠 이미지가 거울처럼 나타나기 때문\n",
    "        img = cv2.flip(img, 1)\n",
    "\n",
    "        # 어떤 제스쳐를 학습시킬 것인지 표시\n",
    "        cv2.putText(img, f'Waiting for collecting {action.upper()} action...', org=(10,30),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)\n",
    "        \n",
    "        #3초동안 대기\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(3000)\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #30초동안 촬영\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # opencv는 기본적으로 BGR로 영상을 읽기 때문에 RGB로 바꿔야 함\n",
    "            result = hands.process(img) # RGB로 바꾼 데이터를 result에 저장\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result.multi_hand_landmarks is not None:\n",
    "                for res in result.multi_hand_landmarks:\n",
    "                    joint = np.zeros((21,4))\n",
    "                    for j,lm in enumerate(res.landmark):\n",
    "                        joint[j] = [lm.x, lm.y, lm.z, lm.visibility] # 각 점의 x, y, z 좌표 & 점이 이미지 상에서 보이는지 안 보이는지\n",
    "\n",
    "                    # 점들 간의 각도 계산하기\n",
    "                    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                    v = v2 - v1 # v2와 v1 사이의 벡터 구하기\n",
    "\n",
    "                    # 벡터 정규화 시키기(단위 벡터 구하기)\n",
    "                    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                    # 점곱을 구한 다음 arccos으로 각도 구하기\n",
    "                    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "                    angle = np.degrees(angle) # 라디안을 각도로 바꾸기\n",
    "\n",
    "                    angle_label = np.array([angle], dtype=np.float32)\n",
    "                    angle_label = np.append(angle_label, idx) # 라벨 추가\n",
    "\n",
    "                    d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "                    data.append(d)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS) # 랜드마크 그리기\n",
    "            \n",
    "            cv2.imshow('img', img)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        data = np.array(data)\n",
    "        print(action, data.shape)\n",
    "        np.save(os.path.join(dirpath+'dataset', f'raw_{action}_{created_time}'),data)\n",
    "\n",
    "        # 시퀀스 데이터로 변환\n",
    "        full_seq_data = []\n",
    "        for seq in range(len(data) - seq_length):\n",
    "            full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        full_seq_data = np.array(full_seq_data)\n",
    "        print(action, full_seq_data.shape)\n",
    "        np.save(os.path.join(dirpath+'dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seq_Next_1689234345.npy', 'seq_Preview_1689234345.npy', 'seq_Cam_Off_1689234345.npy', 'seq_Cam_On_1689234345.npy']\n",
      "(442, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "folder_path = './data/Mini_Project/motion/dataset/'\n",
    "\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On']\n",
    "\n",
    "# \"seq\"가 포함된 파일 리스트를 가져옵니다.\n",
    "file_list = [file for file in os.listdir(folder_path) if 'seq' in file] \n",
    "# actions 리스트 순서대로 정렬\n",
    "file_list.sort(key=lambda x: [actions.index(a) for a in actions if a in x]) \n",
    "\n",
    "sequences = []\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    sequence = np.load(file_path)\n",
    "    sequences.append(sequence)\n",
    "\n",
    "data = np.concatenate(sequences, axis=0)\n",
    "print(file_list)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On']\n",
    "# './data/Mini_Project/motion/dataset/'\n",
    "# # numpy 배열 합치기\n",
    "# data = np.concatenate([np.load('./dataset/seq_zero_1689059738.npy'),\n",
    "#                        np.load('./dataset/seq_one_1689059738.npy'),\n",
    "#                        np.load('./dataset/seq_two_1689059738.npy'),\n",
    "#                        np.load('./dataset/seq_three_1689059738.npy'),\n",
    "#                        np.load('./dataset/seq_four_1689059738.npy'),\n",
    "#                        np.load('./dataset/seq_five_1689059738.npy')], axis=0)\n",
    "\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 30, 99)\n",
      "(442,)\n",
      "(442, 4)\n"
     ]
    }
   ],
   "source": [
    "# data의 마지막 값이 라벨이므로 x_data와 labels로 나눈기\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# One-hot 인코딩\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 30, 99) (353, 4)\n",
      "(89, 30, 99) (89, 4)\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 64)                41984     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,196\n",
      "Trainable params: 44,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "                    # input_shape = [30, 99], 30 : 윈도우의 크기, 99 : 랜드마크, visibility, 각도\n",
    "model = Sequential([LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "                    Dense(32, activation='relu'),\n",
    "                    Dense(len(actions), activation='softmax')])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[ModelCheckpoint(dirpath+'dataset/models/model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto'),\n",
    "                               ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=14, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(8, 5))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_On\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Preview\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Cam_Off\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_On\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Cam_On\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Next\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Next\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On']\n",
    "seq_length = 30\n",
    "\n",
    "model = load_model('./data/Mini_Project/motion/dataset/models/model.h5')\n",
    "\n",
    "# MediaPipe hands model (초기화)\n",
    "mp_hands = mp.solutions.hands\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence=0.9,\n",
    "    min_tracking_confidence=0.9)\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "seq = []\n",
    "action_seq = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img0 = img.copy()\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            joint = np.zeros((21,4))\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "            # 점들 간의 각도 계산하기\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # v2와 v1 사이의 벡터 구하기\n",
    "\n",
    "            # 점곱을 구한 다음 arccos으로 각도 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle) # 라디안을 각도로 바꾸기\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "\n",
    "            seq.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "\n",
    "            # 모델 예측\n",
    "            y_pred = model.predict(input_data).squeeze()\n",
    "\n",
    "            # 예측한 값의 인덱스 구하기\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "\n",
    "            # confidence가 0.9보다 작으면\n",
    "            if conf < 0.99:\n",
    "                continue # 제스쳐 인식 못 한 상황으로 판단\n",
    "\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action) # action_seq에 action을 저장\n",
    "            #print(action_seq)\n",
    "            # 보인 제스쳐의 횟수가 3 미만인 경우에는 계속\n",
    "            if len(action_seq) < 3:\n",
    "                continue\n",
    "            # 제스쳐 판단 불가이면 this_action은 ?\n",
    "            this_action = '?'\n",
    "            # 만약 마지막 3개의 제스쳐가 같으면 제스쳐가 제대로 취해졌다고 판단\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "                print(this_action)\n",
    "            # 텍스트 출력\n",
    "            cv2.putText(img, f'{this_action.upper()}', org=(int(res.landmark[0].x * img.shape[1]), \n",
    "                                                            int(res.landmark[0].y * img.shape[0] + 20)), \n",
    "                                                            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, \n",
    "                                                            color=(255, 255, 255), thickness=2)\n",
    "    # out.write(img0)\n",
    "    # out2.write(img)\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경변경을 모션으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 세그먼트를 위한 YOLOv8 모델 로드\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "# 모션인식을 위한 모델 로드\n",
    "gesture = load_model('./data/Mini_Project/motion/dataset/models/model.h5')\n",
    "first_hand_detection = True\n",
    "# MediaPipe hands model (초기화)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 배경을 불러오기\n",
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "file_count = len(file_list)  # 파일 개수 계산\n",
    "idx = 0 # 파일 리스트를 적절히 초기화해야 함\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On'] # 모션 인식 레이블\n",
    "seq_length = 30\n",
    "seq = []\n",
    "action_seq = []\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "first_hand_detection = True\n",
    "\n",
    "\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "    hand_frame = frame.copy()\n",
    "    # ret, img = cap.read()\n",
    "    # img0 = img.copy()\n",
    "\n",
    "    # hand_frame = cv2.flip(hand_frame, 1)\n",
    "    # hand_frame = cv2.cvtColor(hand_frame, cv2.COLOR_BGR2RGB)\n",
    "    # result = hands.process(img)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행\n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0, verbose=False)\n",
    "        handresult = hands.process(hand_frame)\n",
    "        \n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        blackscreen = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        \n",
    "        try: # 사람이 탐지되지않으면 오류나는것을 방지\n",
    "            for result in results:\n",
    "                # print(result.names) # 탐지 객체 목록 딕셔너리\n",
    "                # if result.boxes.conf >= 0.80:\n",
    "                    # print(result.boxes.conf)\n",
    "                    # if result.probs is not None and result.probs.top1 == 1:\n",
    "                    for mask in result.masks:\n",
    "                        # 마스크 데이터에서 차원 축소\n",
    "                        m = torch.squeeze(mask.data)\n",
    "                        # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                        composite = torch.stack((m, m, m), 2)\n",
    "                        # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                        tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                        # 추출된 마스크 영역을 배경에 누적\n",
    "                        # 미리 생성해둔 검은 배경에 세그먼트된 영역을 채워넣음\n",
    "                        background += tmp\n",
    "                # else:\n",
    "                #     # results = model(frame, classes=0)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if handresult.multi_hand_landmarks is not None:\n",
    "            for res in handresult.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "                    \n",
    "            # 점들 간의 각도 계산하기\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # v2와 v1 사이의 벡터 구하기\n",
    "\n",
    "            # 점곱을 구한 다음 arccos으로 각도 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            \n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            angle = np.degrees(angle) # 라디안을 각도로 바꾸기\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "            seq.append(d)\n",
    "            # mp_drawing.draw_landmarks(frame, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "            # 모델 예측\n",
    "            y_pred = gesture.predict(input_data).squeeze()\n",
    "            # 예측한 값의 인덱스 구하기\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "            # confidence가 0.9보다 작으면\n",
    "            if conf < 0.9:\n",
    "                continue # 제스쳐 인식 못 한 상황으로 판단\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action) # action_seq에 action을 저장\n",
    "            #print(action_seq)\n",
    "            # 보인 제스쳐의 횟수가 3 미만인 경우에는 계속\n",
    "            if len(action_seq) < 30:\n",
    "                continue\n",
    "            # 만약 마지막 3개의 제스쳐가 같으면 제스쳐가 제대로 취해졌다고 판단\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "                # # print(this_action)\n",
    "                if action == 'Next':\n",
    "                        idx += 1\n",
    "                        if idx >= len(file_list):\n",
    "                            idx = 0\n",
    "                        # time.sleep(0.05)\n",
    "                elif action == 'Preview':\n",
    "                        idx -= 1\n",
    "                        if idx < 0:\n",
    "                            idx = len(file_list) - 1\n",
    "                        # time.sleep(0.05)\n",
    "                # elif action == 'Cam_Off':\n",
    "                #     background_copy = background\n",
    "                #     background = bgimg_resized\n",
    "                # elif action == 'Cam_On':\n",
    "                    # background = background_copy\n",
    "            \n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg = cv2.imread(file_list[idx])\n",
    "        bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        # 검정색배경에 세그먼트된 영상에서 0인값을 설정해둔 배경으로 마스킹\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "        # background = cv2.resize(background, (960,720))\n",
    "        background = background.astype(np.uint8)\n",
    "        # 마스킹된 이미지 출력\n",
    "        if first_hand_detection:\n",
    "            if handresult.multi_hand_landmarks is None:\n",
    "                cv2.imshow(\"Project\", blackscreen)\n",
    "            else:\n",
    "                first_hand_detection = False\n",
    "                cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "        else:\n",
    "            cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "            \n",
    "        # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "            break\n",
    "        # 'c' 키가 눌리면 다음 배경\n",
    "        elif key == 99: # ord(\"c\")\n",
    "            idx += 1\n",
    "            if idx >= len(file_list):\n",
    "                idx = 0\n",
    "        # 'z' 키가 눌리면 이전 배경\n",
    "        elif key == 122: # ord(\"z\")\n",
    "            idx -= 1\n",
    "            if idx < 0:\n",
    "                idx = len(file_list) - 1\n",
    "\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 세그먼트를 위한 YOLOv8 모델 로드\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "# 모션인식을 위한 모델 로드\n",
    "gesture = load_model('./data/Mini_Project/motion/dataset/models/model.h5')\n",
    "\n",
    "# MediaPipe hands model (초기화)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "gesture_start = False  # 제스처 인식 시작 여부를 나타내는 변수\n",
    "gesture_end = False  # 제스처 인식 종료 여부를 나타내는 변수\n",
    "gesture_duration = 0  # 제스처 인식 지속 시간을 나타내는 변수 (프레임 수)\n",
    "is_gesture_detected = False  # 제스처 중첩 인식 방지를 위한 변수\n",
    "\n",
    "# 배경을 불러오기\n",
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "file_count = len(file_list)  # 파일 개수 계산\n",
    "idx = 0 # 파일 리스트를 적절히 초기화해야 함\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On'] # 모션 인식 레이블\n",
    "seq_length = 30\n",
    "seq = []\n",
    "action_seq = []\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "first_hand_detection = True\n",
    "\n",
    "\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # start = time.time()\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "    hand_frame = frame.copy()\n",
    "    hand_frame = cv2.cvtColor(hand_frame, cv2.COLOR_RGB2BGR)\n",
    "    # ret, img = cap.read()\n",
    "    # img0 = img.copy()\n",
    "\n",
    "    # hand_frame = cv2.flip(hand_frame, 1)\n",
    "    # hand_frame = cv2.cvtColor(hand_frame, cv2.COLOR_BGR2RGB)\n",
    "    # result = hands.process(img)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행\n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0, verbose=False)\n",
    "        handresult = hands.process(hand_frame)\n",
    "        # handresult = cv\n",
    "        \n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        blackscreen = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        \n",
    "        try: # 사람이 탐지되지않으면 오류나는것을 방지\n",
    "            for result in results:\n",
    "                # print(result.names) # 탐지 객체 목록 딕셔너리\n",
    "                # if result.boxes.conf >= 0.80:\n",
    "                    # print(result.boxes.conf)\n",
    "                    # if result.probs is not None and result.probs.top1 == 1:\n",
    "                    for mask in result.masks:\n",
    "                        # 마스크 데이터에서 차원 축소\n",
    "                        m = torch.squeeze(mask.data)\n",
    "                        # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                        composite = torch.stack((m, m, m), 2)\n",
    "                        # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                        tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                        # 추출된 마스크 영역을 배경에 누적\n",
    "                        # 미리 생성해둔 검은 배경에 세그먼트된 영역을 채워넣음\n",
    "                        background += tmp\n",
    "                # else:\n",
    "                #     # results = model(frame, classes=0)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if handresult.multi_hand_landmarks is not None:\n",
    "            for res in handresult.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "                    \n",
    "            # 점들 간의 각도 계산하기\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # v2와 v1 사이의 벡터 구하기\n",
    "\n",
    "            # 점곱을 구한 다음 arccos으로 각도 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            \n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            angle = np.degrees(angle) # 라디안을 각도로 바꾸기\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "            seq.append(d)\n",
    "            # mp_drawing.draw_landmarks(frame, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "            # 모델 예측\n",
    "            y_pred = gesture.predict(input_data).squeeze()\n",
    "            # 예측한 값의 인덱스 구하기\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "            # confidence가 0.9보다 작으면\n",
    "            if conf < 0.7:\n",
    "                continue # 제스쳐 인식 못 한 상황으로 판단\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action) # action_seq에 action을 저장\n",
    "            #print(action_seq)\n",
    "            # 보인 제스쳐의 횟수가 3 미만인 경우에는 계속\n",
    "            if len(action_seq) < 3:\n",
    "                continue\n",
    "            # 만약 마지막 3개의 제스쳐가 같으면 제스쳐가 제대로 취해졌다고 판단\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "                # # print(this_action)\n",
    "                if action == 'Next':\n",
    "                    if not is_gesture_detected:  # 중첩 인식 방지 변수 확인\n",
    "                        idx += 1\n",
    "                        if idx >= len(file_list):\n",
    "                            idx = 0\n",
    "                        is_gesture_detected = True  # 중첩 인식 방지 변수 설정\n",
    "                elif action == 'Preview':\n",
    "                    if not is_gesture_detected:  # 중첩 인식 방지 변수 확인\n",
    "                        idx -= 1\n",
    "                        if idx < 0:\n",
    "                            idx = len(file_list) - 1\n",
    "                        is_gesture_detected = True  # 중첩 인식 방지 변수 설정\n",
    "                elif action == 'Cam_off':\n",
    "                    cv2.imshow(\"Project\", blackscreen)\n",
    "                    is_gesture_detected = True  # 중첩 인식 방지 변수 설정\n",
    "                elif action == 'cam_On':\n",
    "                    cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "                    is_gesture_detected = True  # 중첩 인식 방지 변수 설정\n",
    "                else:\n",
    "                    gesture_start = False  # 제스처 인식 시작 여부를 나타내는 변수\n",
    "                    gesture_end = False  # 제스처 인식 종료 여부를 나타내는 변수\n",
    "                    gesture_duration = 0  # 제스처 인식 지속 시간을 나타내는 변수 (프레임 수)\n",
    "                    is_gesture_detected = False  # 제스처 중첩 인식 방지를 위한 변수\n",
    "                # elif action == 'Cam_Off':\n",
    "                #     background_copy = background\n",
    "                #     background = bgimg_resized\n",
    "                # elif action == 'Cam_On':\n",
    "                    # background = background_copy\n",
    "            \n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg = cv2.imread(file_list[idx])\n",
    "        bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        # 검정색배경에 세그먼트된 영상에서 0인값을 설정해둔 배경으로 마스킹\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "        # background = cv2.resize(background, (960,720))\n",
    "        background = background.astype(np.uint8)\n",
    "        # 마스킹된 이미지 출력\n",
    "        if first_hand_detection:\n",
    "            if handresult.multi_hand_landmarks is None:\n",
    "                cv2.imshow(\"Project\", blackscreen)\n",
    "            else:\n",
    "                first_hand_detection = False\n",
    "                cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "        else:\n",
    "            cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "            break\n",
    "        # 'c' 키가 눌리면 다음 배경\n",
    "        elif key == 99: # ord(\"c\")\n",
    "            idx += 1\n",
    "            if idx >= len(file_list):\n",
    "                idx = 0\n",
    "        # 'z' 키가 눌리면 이전 배경\n",
    "        elif key == 122: # ord(\"z\")\n",
    "            idx -= 1\n",
    "            if idx < 0:\n",
    "                idx = len(file_list) - 1\n",
    "        # end = time.time()\n",
    "        # print(end - start)\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def get_Background_Image_list(path):\n",
    "    file_list = glob.glob(path + '/*') # 전달받은 폴더 경로로부터 파일 목록을 가져옴\n",
    "    file_count = len(file_list) # 파일 개수 계산\n",
    "    # idx = 0 # 파일 리스트에서 사용할 인덱스번호 초기화\n",
    "    print(f'폴더 내 파일 개수 : {file_count}') # 폴더내의 파일 개수 확인\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def Background_Image_load(file_list, idx, frame):\n",
    "    bgimg = cv2.imread(file_list[idx]) # 파일리스트에서 idx번호의 파일 이미지를 불러옴\n",
    "    bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0])) # 불러온 이미지를 frame사이즈와 같게 리사이즈\n",
    "    return bgimg_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_and_action(key, action):\n",
    "    # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "            return 'Exit'\n",
    "        # 'c' 키가 눌리면 다음 배경\n",
    "        elif key == 99 or action == 'Next': # ord(\"c\")\n",
    "            return 'Next'\n",
    "        # 'z' 키가 눌리면 이전 배경\n",
    "        elif key == 122 or action == 'Preview': # ord(\"z\")\n",
    "            return 'Preview'\n",
    "        else:\n",
    "            return 'Continue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_Background_Image_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m folder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/background\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# 폴더 경로 설정\u001b[39;00m\n\u001b[0;32m     18\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[1;32m---> 19\u001b[0m file_list \u001b[39m=\u001b[39m get_Background_Image_list(folder_path) \u001b[39m# 폴더 경로를 입력받아 폴더 내의 파일 리스트를 받아옴\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# file_count = len(file_list)  # 파일 개수 계산\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# idx = 0 # 파일 리스트를 적절히 초기화해야 함\u001b[39;00m\n\u001b[0;32m     23\u001b[0m actions \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mNext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPreview\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCam_Off\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCam_On\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# 모션 인식 레이블\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_Background_Image_list' is not defined"
     ]
    }
   ],
   "source": [
    "# global idx\n",
    "# 세그먼트를 위한 YOLOv8 모델 로드\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "# 모션인식을 위한 모델 로드\n",
    "gesture = load_model('./data/Mini_Project/motion/dataset/models/model.h5')\n",
    "\n",
    "# MediaPipe hands model (초기화)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 배경을 불러오기\n",
    "folder_path = './data/background'  # 폴더 경로 설정\n",
    "idx = 0 \n",
    "file_list = get_Background_Image_list(folder_path) # 폴더 경로를 입력받아 폴더 내의 파일 리스트를 받아옴\n",
    "# file_list = glob.glob(folder_path + '/*')  # 폴더 내의 파일 목록 얻기\n",
    "# file_count = len(file_list)  # 파일 개수 계산\n",
    "# idx = 0 # 파일 리스트를 적절히 초기화해야 함\n",
    "actions = ['Next', 'Preview', 'Cam_Off', 'Cam_On'] # 모션 인식 레이블\n",
    "seq = []\n",
    "action_seq = []\n",
    "# 웹캠을 위한 비디오 캡처 객체 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "start = time.time()\n",
    "# 비디오 프레임을 반복하여 처리\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 프레임 읽기\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # YOLOv8를 사용하여 프레임에 대한 추론 실행\n",
    "        # classes를 통해 사람만 탐지하도록 설정\n",
    "        results = model(frame, classes=0, verbose=False)\n",
    "        # 검정색 배경 이미지 생성\n",
    "        background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "        \n",
    "        try: # 사람이 탐지되지않으면 오류나는것을 방지\n",
    "            for result in results:\n",
    "                # print(result.names) # 탐지 객체 목록 딕셔너리\n",
    "                # if result.boxes.conf >= 0.80:\n",
    "                    # print(result.boxes.conf)\n",
    "                    # if result.probs is not None and result.probs.top1 == 1:\n",
    "                    for mask in result.masks:\n",
    "                        # 마스크 데이터에서 차원 축소\n",
    "                        m = torch.squeeze(mask.data)\n",
    "                        # 마스크를 RGB 형식으로 변환하여 컴포지트(composite) 텐서 생성\n",
    "                        composite = torch.stack((m, m, m), 2)\n",
    "                        # 프레임과 컴포지트를 곱하여 마스크 영역 추출\n",
    "                        tmp = frame * composite.cpu().numpy().astype(np.uint8)\n",
    "                        # 추출된 마스크 영역을 배경에 누적\n",
    "                        # 미리 생성해둔 검은 배경에 세그먼트된 영역을 채워넣음\n",
    "                        background += tmp\n",
    "                # else:\n",
    "                #     # results = model(frame, classes=0)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        handresult = hands.process(frame)\n",
    "        \n",
    "        if handresult.multi_hand_landmarks is not None:\n",
    "            for res in handresult.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "                    \n",
    "            # 점들 간의 각도 계산하기\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # v2와 v1 사이의 벡터 구하기\n",
    "\n",
    "            # 점곱을 구한 다음 arccos으로 각도 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            \n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            angle = np.degrees(angle) # 라디안을 각도로 바꾸기\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "            seq.append(d)\n",
    "            mp_drawing.draw_landmarks(frame, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "            # 모델 예측\n",
    "            y_pred = gesture.predict(input_data).squeeze()\n",
    "            # 예측한 값의 인덱스 구하기\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "            # confidence가 0.9보다 작으면\n",
    "            if conf < 0.9:\n",
    "                continue # 제스쳐 인식 못 한 상황으로 판단\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action) # action_seq에 action을 저장\n",
    "            #print(action_seq)\n",
    "            # 보인 제스쳐의 횟수가 3 미만인 경우에는 계속\n",
    "            if len(action_seq) < 3:\n",
    "                continue\n",
    "            # 만약 마지막 3개의 제스쳐가 같으면 제스쳐가 제대로 취해졌다고 판단\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "                # # print(this_action)\n",
    "                # if action == 'Next':\n",
    "                #         idx += 1\n",
    "                #         if idx >= len(file_list):\n",
    "                #             idx = 0\n",
    "                #         # time.sleep(0.3)\n",
    "                # elif action == 'Preview':\n",
    "                #         idx -= 1\n",
    "                #         if idx < 0:\n",
    "                #             idx = len(file_list) - 1\n",
    "                            # time.sleep(0.3)\n",
    "                # elif action == 'Cam_Off':\n",
    "                #     background_copy = background\n",
    "                #     background = bgimg_resized\n",
    "                # elif action == 'Cam_On':\n",
    "                    # background = background_copy\n",
    "            \n",
    "        # 배경 이미지를 원하는 배경으로 마스킹\n",
    "        bgimg_resized = Background_Image_load(file_list, idx, frame) # 인덱스 번호에 맞는 배경 이미지를 frame과 같은 사이즈로 조정해 반환\n",
    "        # bgimg = cv2.imread(file_list[idx])\n",
    "        # bgimg_resized = cv2.resize(bgimg, (frame.shape[1], frame.shape[0]))\n",
    "        # 검정색배경에 세그먼트된 영상에서 0인값을 설정해둔 배경으로 마스킹\n",
    "        background = np.where(background == 0, bgimg_resized, background)\n",
    "        # background = cv2.resize(background, (960,720))\n",
    "        background = background.astype(np.uint8)\n",
    "        # 마스킹된 이미지 출력\n",
    "        cv2.imshow(\"Project\", cv2.flip(background, 1)) # 좌우반전\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        action = 'continue'\n",
    "        input_command = key_and_action(key, action) # key값과 action값에 따라 명령 할당\n",
    "        if input_command == 'Exit':\n",
    "            break\n",
    "        elif input_command == 'Next':\n",
    "            idx += 1\n",
    "            if idx >= len(file_list):\n",
    "                idx = 0\n",
    "        elif input_command == 'Preview':\n",
    "            idx -= 1\n",
    "            if idx < 0:\n",
    "                idx = len(file_list) - 1\n",
    "            \n",
    "        # # 'q', 'esc', x버튼 키가 눌리면 루프 종료\n",
    "        # if key == 113 or key == 27 or cv2.getWindowProperty('Project', cv2.WND_PROP_VISIBLE) < 1: # ord(\"q\")\n",
    "        #     break\n",
    "        # # 'c' 키가 눌리면 다음 배경\n",
    "        # elif key == 99: # ord(\"c\")\n",
    "        #     idx += 1\n",
    "        #     if idx >= len(file_list):\n",
    "        #         idx = 0\n",
    "        # # 'z' 키가 눌리면 이전 배경\n",
    "        # elif key == 122: # ord(\"z\")\n",
    "        #     idx -= 1\n",
    "        #     if idx < 0:\n",
    "        #         idx = len(file_list) - 1\n",
    "        end = time.time()\n",
    "        print(start - end)\n",
    "    else:\n",
    "        # 비디오의 끝에 도달하면 루프 종료\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체 해제 및 화면 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
